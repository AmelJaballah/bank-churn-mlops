"""
Bank Churn Prediction - Streamlit Interface
Application web pour la prÃ©diction de dÃ©faillance client (churn)
"""

import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, Any
import os
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="Bank Churn Prediction",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# URL de l'API (variable d'environnement ou valeur par dÃ©faut)
API_URL = os.getenv("API_URL", "https://bank-churn.salmonbay-9a939e1f.francecentral.azurecontainerapps.io")

# CSS personnalisÃ© amÃ©liorÃ©
st.markdown("""
<style>
    /* Global Styling */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Header Styling */
    .main-header {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(90deg, #ffffff, #e0e7ff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .sub-header {
        color: rgba(255,255,255,0.8);
        text-align: center;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    /* Card Styling */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border-radius: 20px;
        padding: 25px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.18);
        margin-bottom: 1rem;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 20px;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: bold;
        color: #1f2937;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #6b7280;
        margin-top: 5px;
    }
    
    /* Risk Badges */
    .risk-badge {
        display: inline-block;
        padding: 8px 20px;
        border-radius: 25px;
        font-weight: bold;
        font-size: 1rem;
    }
    
    .risk-low { background: linear-gradient(135deg, #10b981, #059669); color: white; }
    .risk-medium { background: linear-gradient(135deg, #f59e0b, #d97706); color: white; }
    .risk-high { background: linear-gradient(135deg, #ef4444, #dc2626); color: white; }
    
    /* Drift Status */
    .drift-ok { background: linear-gradient(135deg, #10b981, #059669); color: white; padding: 10px 20px; border-radius: 10px; }
    .drift-warning { background: linear-gradient(135deg, #f59e0b, #d97706); color: white; padding: 10px 20px; border-radius: 10px; }
    .drift-critical { background: linear-gradient(135deg, #ef4444, #dc2626); color: white; padding: 10px 20px; border-radius: 10px; }
    
    /* Button Styling */
    .stButton > button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-size: 1.1rem;
        font-weight: 600;
        padding: 0.75rem 2rem;
        border-radius: 12px;
        border: none;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
    }
    
    /* Sidebar Styling */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1e1e2e 0%, #2d2d44 100%);
    }
    
    [data-testid="stSidebar"] .stMarkdown {
        color: white;
    }
    
    /* Tab Styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: rgba(255,255,255,0.1);
        border-radius: 12px;
        padding: 5px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 10px;
        color: white;
        font-weight: 500;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    /* Footer */
    .footer {
        text-align: center;
        color: rgba(255,255,255,0.7);
        padding: 20px;
        margin-top: 2rem;
    }
    
    /* Animations */
    @keyframes pulse {
        0% { transform: scale(1); }
        50% { transform: scale(1.05); }
        100% { transform: scale(1); }
    }
    
    .pulse { animation: pulse 2s infinite; }
</style>
""", unsafe_allow_html=True)

def check_api_health() -> bool:
    """VÃ©rifie si l'API est disponible"""
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        return response.status_code == 200
    except:
        return False

def get_api_info() -> Dict[str, Any]:
    """RÃ©cupÃ¨re les infos de l'API"""
    try:
        response = requests.get(f"{API_URL}/", timeout=5)
        return response.json()
    except:
        return None

def make_prediction(features: Dict[str, Any]) -> Dict[str, Any]:
    """Envoie une requÃªte de prÃ©diction Ã  l'API"""
    try:
        # Convert all values to int/float as needed
        payload = {
            "CreditScore": int(features["CreditScore"]),
            "Age": int(features["Age"]),
            "Tenure": int(features["Tenure"]),
            "Balance": float(features["Balance"]),
            "NumOfProducts": int(features["NumOfProducts"]),
            "HasCrCard": int(features["HasCrCard"]),
            "IsActiveMember": int(features["IsActiveMember"]),
            "EstimatedSalary": float(features["EstimatedSalary"]),
            "Geography_Germany": int(features["Geography_Germany"]),
            "Geography_Spain": int(features["Geography_Spain"])
        }
        
        response = requests.post(
            f"{API_URL}/predict",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Erreur de connexion Ã  l'API: {e}")
        return None

def check_drift() -> Dict[str, Any]:
    """VÃ©rifie le drift des donnÃ©es via l'API"""
    try:
        response = requests.post(f"{API_URL}/drift/check", timeout=30)
        return response.json()
    except:
        return None

def generate_synthetic_drift_data(reference_data: pd.DataFrame, drift_intensity: float = 0.3) -> pd.DataFrame:
    """GÃ©nÃ¨re des donnÃ©es synthÃ©tiques avec drift - Structure complÃ¨te"""
    n_samples = min(500, len(reference_data))
    
    # Si les donnÃ©es de rÃ©fÃ©rence n'ont pas toutes les colonnes, gÃ©nÃ©rer un dataset complet
    required_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 
                     'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 
                     'Geography_Germany', 'Geography_Spain']
    
    if not all(col in reference_data.columns for col in required_cols):
        # GÃ©nÃ©rer des donnÃ©es synthÃ©tiques complÃ¨tes
        np.random.seed(None)  # Random seed pour variation
        prod_data = pd.DataFrame({
            'CreditScore': np.random.normal(650, 100, n_samples),
            'Age': np.random.normal(40, 12, n_samples),
            'Tenure': np.random.randint(0, 11, n_samples),
            'Balance': np.abs(np.random.normal(75000, 50000, n_samples)),
            'NumOfProducts': np.random.choice([1, 2, 3, 4], n_samples, p=[0.5, 0.4, 0.08, 0.02]),
            'HasCrCard': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
            'IsActiveMember': np.random.choice([0, 1], n_samples, p=[0.4, 0.6]),
            'EstimatedSalary': np.random.normal(100000, 50000, n_samples),
            'Geography_Germany': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),
            'Geography_Spain': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])
        })
    else:
        # Copier depuis les donnÃ©es de rÃ©fÃ©rence
        prod_data = reference_data[required_cols].sample(n=n_samples, replace=True).copy()
    
    # Appliquer le drift sur les features numÃ©riques continues
    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']
    
    for feature in numerical_features:
        if feature in prod_data.columns:
            mean_shift = prod_data[feature].std() * drift_intensity * np.random.choice([-1, 1])
            prod_data[feature] = prod_data[feature] + mean_shift
            noise = np.random.normal(0, prod_data[feature].std() * drift_intensity * 0.3, len(prod_data))
            prod_data[feature] = prod_data[feature] + noise
    
    # S'assurer que NumOfProducts reste dans les limites
    prod_data['NumOfProducts'] = prod_data['NumOfProducts'].clip(1, 4).astype(int)
    
    # S'assurer que les features binaires restent 0 ou 1
    for col in ['HasCrCard', 'IsActiveMember', 'Geography_Germany', 'Geography_Spain']:
        prod_data[col] = prod_data[col].round().clip(0, 1).astype(int)
    
    # S'assurer que CreditScore reste dans les limites rÃ©alistes
    prod_data['CreditScore'] = prod_data['CreditScore'].clip(300, 850).astype(int)
    
    # S'assurer que Age reste dans les limites
    prod_data['Age'] = prod_data['Age'].clip(18, 100).astype(int)
    
    # S'assurer que Tenure reste dans les limites
    prod_data['Tenure'] = prod_data['Tenure'].clip(0, 10).astype(int)
    
    # S'assurer que Balance et Salary sont positifs
    prod_data['Balance'] = prod_data['Balance'].clip(0, None)
    prod_data['EstimatedSalary'] = prod_data['EstimatedSalary'].clip(0, None)
    
    return prod_data

def calculate_psi(reference: np.array, production: np.array, buckets: int = 10) -> float:
    """Calculate Population Stability Index"""
    min_val = min(reference.min(), production.min())
    max_val = max(reference.max(), production.max())
    breakpoints = np.linspace(min_val, max_val, buckets + 1)
    
    ref_counts = np.histogram(reference, bins=breakpoints)[0]
    prod_counts = np.histogram(production, bins=breakpoints)[0]
    
    ref_pct = (ref_counts + 0.0001) / len(reference)
    prod_pct = (prod_counts + 0.0001) / len(production)
    
    psi = np.sum((prod_pct - ref_pct) * np.log(prod_pct / ref_pct))
    return float(psi)

def detect_outliers(data: pd.DataFrame, feature: str) -> Dict[str, Any]:
    """DÃ©tecte les valeurs extrÃªmes avec la mÃ©thode IQR"""
    Q1 = data[feature].quantile(0.25)
    Q3 = data[feature].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 3 * IQR
    upper_bound = Q3 + 3 * IQR
    
    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)]
    
    return {
        'count': len(outliers),
        'percentage': len(outliers) / len(data) * 100,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound,
        'min_value': data[feature].min(),
        'max_value': data[feature].max()
    }

def analyze_prediction_drift(ref_data: pd.DataFrame, prod_data: pd.DataFrame, api_url: str) -> Dict[str, Any]:
    """Analyse l'impact du drift sur les prÃ©dictions"""
    # Sample rÃ©duit pour ne pas surcharger l'API
    ref_sample = ref_data.sample(min(20, len(ref_data)))
    prod_sample = prod_data.sample(min(20, len(prod_data)))
    
    ref_predictions = []
    prod_predictions = []
    
    def prepare_features(row):
        """PrÃ©pare et valide les features pour l'API"""
        try:
            # Nettoyer et convertir les valeurs
            feat = {
                'CreditScore': int(float(row.get('CreditScore', 650))),
                'Age': int(float(row.get('Age', 40))),
                'Tenure': int(float(row.get('Tenure', 5))),
                'Balance': float(row.get('Balance', 50000)),
                'NumOfProducts': int(float(row.get('NumOfProducts', 2))),
                'HasCrCard': int(float(row.get('HasCrCard', 1))),
                'IsActiveMember': int(float(row.get('IsActiveMember', 1))),
                'EstimatedSalary': float(row.get('EstimatedSalary', 75000)),
                'Geography_Germany': int(float(row.get('Geography_Germany', 0))),
                'Geography_Spain': int(float(row.get('Geography_Spain', 0)))
            }
            
            # Valider les ranges
            feat['CreditScore'] = max(300, min(850, feat['CreditScore']))
            feat['Age'] = max(18, min(100, feat['Age']))
            feat['Tenure'] = max(0, min(10, feat['Tenure']))
            feat['Balance'] = max(0, feat['Balance'])
            feat['NumOfProducts'] = max(1, min(4, feat['NumOfProducts']))
            feat['HasCrCard'] = 1 if feat['HasCrCard'] else 0
            feat['IsActiveMember'] = 1 if feat['IsActiveMember'] else 0
            feat['Geography_Germany'] = 1 if feat['Geography_Germany'] else 0
            feat['Geography_Spain'] = 1 if feat['Geography_Spain'] else 0
            feat['EstimatedSalary'] = max(0, feat['EstimatedSalary'])
            
            # VÃ©rifier qu'il n'y a pas de NaN
            if any(pd.isna(v) or (isinstance(v, float) and np.isnan(v)) for v in feat.values()):
                return None
                
            return feat
        except Exception as e:
            return None
    
    # PrÃ©dictions sur donnÃ©es de rÃ©fÃ©rence
    for _, row in ref_sample.iterrows():
        feat = prepare_features(row)
        if feat:
            try:
                result = make_prediction(feat)
                if result and 'churn_probability' in result:
                    ref_predictions.append(result['churn_probability'])
            except Exception as e:
                continue
    
    # PrÃ©dictions sur donnÃ©es avec drift
    for _, row in prod_sample.iterrows():
        feat = prepare_features(row)
        if feat:
            try:
                result = make_prediction(feat)
                if result and 'churn_probability' in result:
                    prod_predictions.append(result['churn_probability'])
            except Exception as e:
                continue
    
    # Analyser seulement si on a assez de prÃ©dictions
    if len(ref_predictions) >= 5 and len(prod_predictions) >= 5:
        from scipy import stats
        ks_stat, p_value = stats.ks_2samp(ref_predictions, prod_predictions)
        
        return {
            'ref_mean': np.mean(ref_predictions),
            'prod_mean': np.mean(prod_predictions),
            'diff_mean': abs(np.mean(prod_predictions) - np.mean(ref_predictions)),
            'ks_statistic': ks_stat,
            'p_value': p_value,
            'prediction_drift_detected': ks_stat > 0.2 or p_value < 0.05,
            'n_ref': len(ref_predictions),
            'n_prod': len(prod_predictions)
        }
    
    return None

def create_gauge_chart(probability: float) -> go.Figure:
    """CrÃ©e un graphique jauge pour la probabilitÃ© de churn"""
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=probability * 100,
        domain={'x': [0, 1], 'y': [0, 1]},
        number={'suffix': '%', 'font': {'size': 40, 'color': '#1f2937'}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 2, 'tickcolor': "#374151", 'tickfont': {'size': 14}},
            'bar': {'color': "#667eea", 'thickness': 0.75},
            'bgcolor': "white",
            'borderwidth': 3,
            'bordercolor': "#e5e7eb",
            'steps': [
                {'range': [0, 30], 'color': '#d1fae5'},
                {'range': [30, 60], 'color': '#fef3c7'},
                {'range': [60, 100], 'color': '#fee2e2'}
            ],
            'threshold': {
                'line': {'color': "#ef4444", 'width': 4},
                'thickness': 0.8,
                'value': probability * 100
            }
        }
    ))
    fig.update_layout(
        height=280,
        margin=dict(l=30, r=30, t=30, b=10),
        paper_bgcolor='rgba(0,0,0,0)',
        font={'color': '#1f2937'}
    )
    return fig

def create_drift_comparison_chart(ref_data: pd.DataFrame, prod_data: pd.DataFrame, feature: str) -> go.Figure:
    """CrÃ©e un graphique de comparaison entre donnÃ©es de rÃ©fÃ©rence et production"""
    fig = go.Figure()
    
    fig.add_trace(go.Histogram(
        x=ref_data[feature],
        name='RÃ©fÃ©rence',
        opacity=0.7,
        marker_color='#667eea',
        nbinsx=30
    ))
    
    fig.add_trace(go.Histogram(
        x=prod_data[feature],
        name='Production',
        opacity=0.7,
        marker_color='#ef4444',
        nbinsx=30
    ))
    
    fig.update_layout(
        title=f'Distribution: {feature}',
        barmode='overlay',
        height=300,
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        xaxis_title=feature,
        yaxis_title='FrÃ©quence',
        legend=dict(x=0.7, y=0.95),
        margin=dict(l=50, r=20, t=50, b=50)
    )
    
    return fig

def create_drift_summary_chart(drift_results: Dict) -> go.Figure:
    """CrÃ©e un graphique rÃ©sumÃ© du drift"""
    features = list(drift_results.keys())
    psi_values = [drift_results[f]['psi'] for f in features]
    colors = ['#ef4444' if v > 0.25 else '#f59e0b' if v > 0.1 else '#10b981' for v in psi_values]
    
    fig = go.Figure(go.Bar(
        x=psi_values,
        y=features,
        orientation='h',
        marker_color=colors,
        text=[f'{v:.3f}' for v in psi_values],
        textposition='outside'
    ))
    
    # Add threshold lines
    fig.add_vline(x=0.1, line_dash="dash", line_color="#f59e0b", annotation_text="Warning", annotation_position="top")
    fig.add_vline(x=0.25, line_dash="dash", line_color="#ef4444", annotation_text="Critical", annotation_position="top")
    
    fig.update_layout(
        title='PSI par Feature (Population Stability Index)',
        xaxis_title='PSI',
        height=400,
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(255,255,255,0.9)',
        margin=dict(l=120, r=50, t=50, b=50)
    )
    
    return fig

def create_feature_importance_chart(features: Dict[str, Any]) -> go.Figure:
    """CrÃ©e un graphique radar du profil client"""
    # Normalisation pour radar chart
    normalized = {
        'Credit Score': min(features['CreditScore'] / 850 * 100, 100),
        'Ã‚ge': min(features['Age'] / 80 * 100, 100),
        'AnciennetÃ©': min(features['Tenure'] / 10 * 100, 100),
        'Solde': min(features['Balance'] / 200000 * 100, 100),
        'Produits': min(features['NumOfProducts'] / 4 * 100, 100),
        'Engagement': features['IsActiveMember'] * 100,
    }
    
    categories = list(normalized.keys())
    values = list(normalized.values())
    values.append(values[0])  # Close the radar
    categories.append(categories[0])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        fillcolor='rgba(102, 126, 234, 0.3)',
        line=dict(color='#667eea', width=2),
        name='Profil Client'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                tickfont=dict(size=10)
            ),
            angularaxis=dict(tickfont=dict(size=11))
        ),
        showlegend=False,
        height=320,
        margin=dict(l=60, r=60, t=30, b=30),
        paper_bgcolor='rgba(0,0,0,0)'
    )
    return fig
def main():
    # Header
    st.markdown('<h1 class="main-header">ğŸ¦ Bank Churn Prediction</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">PrÃ©diction intelligente de dÃ©faillance client avec dÃ©tection de drift</p>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("## ğŸ”— Ã‰tat du SystÃ¨me")
        api_status = check_api_health()
        api_info = get_api_info()
        
        if api_status:
            st.success("âœ… API ConnectÃ©e")
            if api_info:
                st.info(f"ğŸ“Œ Version: {api_info.get('version', 'N/A')}")
        else:
            st.error("âŒ API Non Disponible")
        
        st.markdown("---")
        
        st.markdown("## ğŸ“Š LÃ©gende des Risques")
        st.markdown("""
        <div style='padding: 10px; background: rgba(255,255,255,0.1); border-radius: 10px;'>
            <p>ğŸŸ¢ <strong>Low</strong>: < 30% de risque</p>
            <p>ğŸŸ¡ <strong>Medium</strong>: 30-60% de risque</p>
            <p>ğŸ”´ <strong>High</strong>: > 60% de risque</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        st.markdown("## â„¹ï¸ Ã€ propos")
        st.markdown("""
        <div style='padding: 10px; background: rgba(255,255,255,0.1); border-radius: 10px; font-size: 0.9rem;'>
            <p><strong>ModÃ¨le:</strong> Random Forest</p>
            <p><strong>Framework:</strong> FastAPI + MLflow</p>
            <p><strong>Cloud:</strong> Azure Container Apps</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Main Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ”® PrÃ©diction", "ğŸ“Š Analyse Drift", "ğŸ“ Batch"])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 1: PREDICTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab1:
        col1, col2 = st.columns([1, 1], gap="large")
        
        with col1:
            st.markdown("### ğŸ“‹ Informations Client")
            
            # Informations personnelles
            st.markdown("#### ğŸ‘¤ Profil Personnel")
            age = st.slider("Ã‚ge", min_value=18, max_value=100, value=35, help="Ã‚ge du client", key="age_tab1")
            
            col_geo1, col_geo2 = st.columns(2)
            with col_geo1:
                geography = st.selectbox(
                    "Pays",
                    options=["France", "Germany", "Spain"],
                    help="Pays de rÃ©sidence du client"
                )
            with col_geo2:
                tenure = st.slider("AnciennetÃ© (annÃ©es)", min_value=0, max_value=10, value=5, key="tenure_tab1")
            
            # Informations financiÃ¨res
            st.markdown("#### ğŸ’° Informations FinanciÃ¨res")
            credit_score = st.slider(
                "Score de CrÃ©dit",
                min_value=300, max_value=850, value=650,
                help="Score de crÃ©dit (300-850)",
                key="credit_tab1"
            )
            
            col_fin1, col_fin2 = st.columns(2)
            with col_fin1:
                balance = st.number_input(
                    "Solde du compte (â‚¬)",
                    min_value=0.0, max_value=500000.0, value=50000.0,
                    step=1000.0,
                    help="Solde actuel du compte"
                )
            with col_fin2:
                estimated_salary = st.number_input(
                    "Salaire estimÃ© (â‚¬)",
                    min_value=0.0, max_value=300000.0, value=75000.0,
                    step=1000.0,
                    help="Salaire annuel estimÃ©"
                )
            
            # Produits et services
            st.markdown("#### ğŸ¦ Produits & Services")
            col_prod1, col_prod2 = st.columns(2)
            with col_prod1:
                num_products = st.selectbox(
                    "Nombre de produits",
                    options=[1, 2, 3, 4],
                    index=1,
                    help="Nombre de produits bancaires"
                )
            with col_prod2:
                has_credit_card = st.checkbox("PossÃ¨de une carte de crÃ©dit", value=True)
            
            is_active_member = st.checkbox("Membre actif", value=True, help="Le client utilise rÃ©guliÃ¨rement ses services")
        
        with col2:
            st.markdown("### ğŸ”® RÃ©sultat de PrÃ©diction")
            
            # Conversion geography
            geography_germany = 1 if geography == "Germany" else 0
            geography_spain = 1 if geography == "Spain" else 0
            
            # PrÃ©paration des features
            features = {
                "CreditScore": credit_score,
                "Age": age,
                "Tenure": tenure,
                "Balance": balance,
                "NumOfProducts": num_products,
                "HasCrCard": 1 if has_credit_card else 0,
                "IsActiveMember": 1 if is_active_member else 0,
                "EstimatedSalary": estimated_salary,
                "Geography_Germany": geography_germany,
                "Geography_Spain": geography_spain
            }
            
            # Bouton de prÃ©diction
            if st.button("ğŸ” Analyser le Risque de Churn", type="primary", key="predict_btn"):
                # VÃ©rification des valeurs extrÃªmes
                warnings = []
                if credit_score < 400 or credit_score > 800:
                    warnings.append("âš ï¸ Credit Score extrÃªme dÃ©tectÃ©")
                if age < 20 or age > 75:
                    warnings.append("âš ï¸ Ã‚ge inhabituel dÃ©tectÃ©")
                if balance > 200000:
                    warnings.append("âš ï¸ Solde trÃ¨s Ã©levÃ© dÃ©tectÃ©")
                if estimated_salary > 200000:
                    warnings.append("âš ï¸ Salaire trÃ¨s Ã©levÃ© dÃ©tectÃ©")
                
                if warnings:
                    st.warning("**Valeurs atypiques dÃ©tectÃ©es:**\n" + "\n".join(warnings))
                    st.caption("Ces valeurs peuvent indiquer un drift ou des donnÃ©es inhabituelles.")
                
                with st.spinner("Analyse en cours..."):
                    result = make_prediction(features)
                    
                    if result:
                        # Affichage des mÃ©triques
                        col_m1, col_m2, col_m3 = st.columns(3)
                        
                        with col_m1:
                            st.metric(
                                label="ProbabilitÃ©",
                                value=f"{result['churn_probability']*100:.1f}%"
                            )
                        
                        with col_m2:
                            pred_text = "ğŸšª DÃ©part" if result['prediction'] == 1 else "âœ… FidÃ¨le"
                            st.metric(label="PrÃ©diction", value=pred_text)
                        
                        with col_m3:
                            risk_colors = {"Low": "ğŸŸ¢", "Medium": "ğŸŸ¡", "High": "ğŸ”´"}
                            st.metric(
                                label="Risque",
                                value=f"{risk_colors.get(result['risk_level'], '')} {result['risk_level']}"
                            )
                        
                        # Graphique jauge
                        st.plotly_chart(create_gauge_chart(result['churn_probability']), use_container_width=True)
                        
                        # Recommandations
                        if result['risk_level'] == "High":
                            st.error("**âš ï¸ Risque Ã©levÃ©!** Contact prioritaire recommandÃ©.")
                        elif result['risk_level'] == "Medium":
                            st.warning("**âš¡ Risque modÃ©rÃ©.** Surveillance recommandÃ©e.")
                        else:
                            st.success("**âœ… Client stable.** Maintenir le suivi habituel.")
                        
                        st.session_state['last_prediction'] = result
            
            # Profil radar
            st.markdown("---")
            st.markdown("#### ğŸ“Š Profil Client")
            st.plotly_chart(create_feature_importance_chart(features), use_container_width=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 2: DRIFT ANALYSIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab2:
        st.markdown("### ğŸ“Š Analyse du Drift des DonnÃ©es")
        st.markdown("DÃ©tectez les changements dans la distribution des donnÃ©es de production par rapport aux donnÃ©es d'entraÃ®nement.")
        
        col_drift1, col_drift2 = st.columns([1, 2])
        
        with col_drift1:
            st.markdown("#### âš™ï¸ Configuration")
            
            drift_intensity = st.slider(
                "IntensitÃ© du drift simulÃ©",
                min_value=0.0, max_value=1.0, value=0.3, step=0.1,
                help="0 = pas de drift, 1 = drift maximum"
            )
            
            n_samples = st.slider(
                "Nombre d'Ã©chantillons",
                min_value=100, max_value=1000, value=500, step=100
            )
            
            if st.button("ğŸ”„ GÃ©nÃ©rer & Analyser le Drift", type="primary", key="drift_btn"):
                with st.spinner("GÃ©nÃ©ration des donnÃ©es et analyse du drift..."):
                    # Load reference data
                    try:
                        ref_data = pd.read_csv("https://raw.githubusercontent.com/AmelJaballah/bank-churn-mlops/main/data/bank_churn.csv")
                    except:
                        # Fallback: generate synthetic reference data avec toutes les colonnes
                        np.random.seed(42)
                        ref_data = pd.DataFrame({
                            'CreditScore': np.random.normal(650, 100, 1000),
                            'Age': np.random.normal(40, 12, 1000),
                            'Tenure': np.random.randint(0, 11, 1000),
                            'Balance': np.abs(np.random.normal(75000, 50000, 1000)),
                            'NumOfProducts': np.random.choice([1, 2, 3, 4], 1000, p=[0.5, 0.4, 0.08, 0.02]),
                            'HasCrCard': np.random.choice([0, 1], 1000, p=[0.3, 0.7]),
                            'IsActiveMember': np.random.choice([0, 1], 1000, p=[0.4, 0.6]),
                            'EstimatedSalary': np.random.normal(100000, 50000, 1000),
                            'Geography_Germany': np.random.choice([0, 1], 1000, p=[0.7, 0.3]),
                            'Geography_Spain': np.random.choice([0, 1], 1000, p=[0.8, 0.2])
                        })
                    
                    # Generate production data with drift
                    prod_data = generate_synthetic_drift_data(ref_data, drift_intensity)
                    
                    # VÃ©rifier la structure des donnÃ©es gÃ©nÃ©rÃ©es
                    st.caption(f"âœ… DonnÃ©es gÃ©nÃ©rÃ©es: {len(prod_data)} Ã©chantillons avec {len(prod_data.columns)} colonnes")
                    
                    # Calculate drift metrics
                    numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
                    drift_results = {}
                    
                    for feature in numerical_features:
                        if feature in ref_data.columns:
                            ref_vals = ref_data[feature].dropna().values
                            prod_vals = prod_data[feature].dropna().values
                            
                            from scipy import stats
                            ks_stat, p_value = stats.ks_2samp(ref_vals, prod_vals)
                            psi = calculate_psi(ref_vals, prod_vals)
                            
                            drift_results[feature] = {
                                'ks_statistic': round(ks_stat, 4),
                                'p_value': round(p_value, 6),
                                'psi': round(psi, 4),
                                'drift_detected': psi > 0.1 or p_value < 0.05
                            }
                    
                    # Store in session state
                    st.session_state['drift_results'] = drift_results
                    st.session_state['ref_data'] = ref_data
                    st.session_state['prod_data'] = prod_data
                    st.session_state['drift_intensity'] = drift_intensity
                    
                    st.success("âœ… Analyse terminÃ©e!")
        
        with col_drift2:
            if 'drift_results' in st.session_state:
                drift_results = st.session_state['drift_results']
                
                # Summary metrics
                drifted = [f for f, r in drift_results.items() if r['drift_detected']]
                drift_pct = len(drifted) / len(drift_results) * 100
                
                col_s1, col_s2, col_s3 = st.columns(3)
                with col_s1:
                    st.metric("Features analysÃ©es", len(drift_results))
                with col_s2:
                    st.metric("Drift dÃ©tectÃ©", len(drifted))
                with col_s3:
                    status = "ğŸŸ¢ OK" if drift_pct < 30 else "ğŸŸ¡ Warning" if drift_pct < 60 else "ğŸ”´ Critical"
                    st.metric("Statut", status)
                
                # PSI Chart
                st.plotly_chart(create_drift_summary_chart(drift_results), use_container_width=True)
        
        # Distribution comparisons
        if 'drift_results' in st.session_state:
            st.markdown("---")
            st.markdown("#### ğŸ“ˆ Comparaison des Distributions")
            
            ref_data = st.session_state['ref_data']
            prod_data = st.session_state['prod_data']
            
            feature_cols = st.columns(3)
            features = ['CreditScore', 'Age', 'Balance']
            
            for i, feature in enumerate(features):
                with feature_cols[i]:
                    if feature in ref_data.columns:
                        st.plotly_chart(
                            create_drift_comparison_chart(ref_data, prod_data, feature),
                            use_container_width=True
                        )
            
            # Detailed table
            st.markdown("#### ğŸ“‹ DÃ©tails par Feature")
            drift_df = pd.DataFrame(st.session_state['drift_results']).T
            drift_df.index.name = 'Feature'
            drift_df = drift_df.reset_index()
            drift_df['Status'] = drift_df['drift_detected'].apply(lambda x: 'ğŸ”´ Drift' if x else 'ğŸŸ¢ Stable')
            st.dataframe(drift_df[['Feature', 'psi', 'ks_statistic', 'p_value', 'Status']], use_container_width=True, hide_index=True)
            
            # Outliers Analysis
            st.markdown("---")
            st.markdown("#### âš ï¸ DÃ©tection des Valeurs ExtrÃªmes")
            
            outlier_results = {}
            for feature in ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']:
                if feature in prod_data.columns:
                    outlier_results[feature] = detect_outliers(prod_data, feature)
            
            col_out1, col_out2 = st.columns(2)
            with col_out1:
                st.markdown("**Outliers dÃ©tectÃ©s:**")
                for feature, info in outlier_results.items():
                    if info['count'] > 0:
                        st.warning(f"ğŸ”¸ **{feature}**: {info['count']} valeurs extrÃªmes ({info['percentage']:.1f}%)")
                        st.caption(f"   Range: [{info['min_value']:.1f}, {info['max_value']:.1f}] | Limites: [{info['lower_bound']:.1f}, {info['upper_bound']:.1f}]")
            
            with col_out2:
                # Analyze prediction drift
                st.markdown("**Impact sur les prÃ©dictions:**")
                with st.spinner("Analyse en cours..."):
                    pred_drift = analyze_prediction_drift(ref_data, prod_data, API_URL)
                    
                    if pred_drift:
                        if pred_drift['prediction_drift_detected']:
                            st.error(f"ğŸš¨ **Drift de prÃ©diction dÃ©tectÃ©!**")
                            st.metric("Ã‰cart moyen proba.", f"{pred_drift['diff_mean']*100:.2f}%")
                        else:
                            st.success("âœ… PrÃ©dictions stables")
                        
                        col_p1, col_p2 = st.columns(2)
                        with col_p1:
                            st.metric("Proba. moy. RÃ©f.", f"{pred_drift['ref_mean']*100:.1f}%")
                        with col_p2:
                            st.metric("Proba. moy. Prod.", f"{pred_drift['prod_mean']*100:.1f}%")
                        
                        st.caption(f"KS stat: {pred_drift['ks_statistic']:.4f} | p-value: {pred_drift['p_value']:.6f}")
                        st.caption(f"Ã‰chantillons: RÃ©f={pred_drift['n_ref']}, Prod={pred_drift['n_prod']}")
                    else:
                        st.warning("âš ï¸ Analyse impossible - DonnÃ©es insuffisantes ou erreur API")
            
            # Export button
            st.markdown("---")
            col_exp1, col_exp2, col_exp3 = st.columns(3)
            with col_exp1:
                csv = drift_df.to_csv(index=False)
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger rapport drift",
                    csv,
                    f"{datetime.now().strftime('%Y-%m-%dT%H-%M')}_drift_report.csv",
                    "text/csv"
                )
            with col_exp2:
                if outlier_results:
                    outlier_df = pd.DataFrame(outlier_results).T
                    outlier_csv = outlier_df.to_csv()
                    st.download_button(
                        "ğŸ“¥ TÃ©lÃ©charger outliers",
                        outlier_csv,
                        f"{datetime.now().strftime('%Y-%m-%dT%H-%M')}_outliers.csv",
                        "text/csv"
                    )
            with col_exp3:
                # Export production data with drift
                prod_csv = prod_data.to_csv(index=False)
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger donnÃ©es drift",
                    prod_csv,
                    f"{datetime.now().strftime('%Y-%m-%dT%H-%M')}_production_data.csv",
                    "text/csv",
                    help="DonnÃ©es de production avec drift appliquÃ©"
                )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 3: BATCH PREDICTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab3:
        st.markdown("### ğŸ“ PrÃ©diction par Lot")
        st.info("TÃ©lÃ©chargez un fichier CSV avec les colonnes: CreditScore, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Geography_Germany, Geography_Spain")
        
        uploaded_file = st.file_uploader("Choisir un fichier CSV", type=['csv'], key="batch_upload")
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.write("**AperÃ§u des donnÃ©es:**")
                st.dataframe(df.head(), use_container_width=True)
                
                # Validate required columns
                required_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 
                                'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 
                                'Geography_Germany', 'Geography_Spain']
                missing_cols = [col for col in required_cols if col not in df.columns]
                
                if missing_cols:
                    st.error(f"âŒ Colonnes manquantes: {', '.join(missing_cols)}")
                else:
                    if st.button("ğŸš€ Lancer l'analyse", type="primary", key="batch_btn"):
                        results = []
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for idx, row in df.iterrows():
                            # Ensure proper data types
                            feat = {
                                'CreditScore': int(row['CreditScore']),
                                'Age': int(row['Age']),
                                'Tenure': int(row['Tenure']),
                                'Balance': float(row['Balance']),
                                'NumOfProducts': int(row['NumOfProducts']),
                                'HasCrCard': int(row['HasCrCard']),
                                'IsActiveMember': int(row['IsActiveMember']),
                                'EstimatedSalary': float(row['EstimatedSalary']),
                                'Geography_Germany': int(row['Geography_Germany']),
                                'Geography_Spain': int(row['Geography_Spain'])
                            }
                            
                            result = make_prediction(feat)
                            if result:
                                results.append({**feat, **result})
                            
                            progress_bar.progress((idx + 1) / len(df))
                            status_text.text(f"Traitement: {idx + 1}/{len(df)}")
                        
                        status_text.empty()
                        
                        if results:
                            results_df = pd.DataFrame(results)
                            
                            col_b1, col_b2, col_b3, col_b4 = st.columns(4)
                            with col_b1:
                                st.metric("Total", len(results))
                            with col_b2:
                                high = len([r for r in results if r['risk_level'] == 'High'])
                                st.metric("Risque Ã©levÃ©", high)
                            with col_b3:
                                med = len([r for r in results if r['risk_level'] == 'Medium'])
                                st.metric("Risque modÃ©rÃ©", med)
                            with col_b4:
                                churn_rate = sum([r['prediction'] for r in results]) / len(results) * 100
                                st.metric("Taux churn", f"{churn_rate:.1f}%")
                            
                            csv = results_df.to_csv(index=False)
                            st.download_button("ğŸ“¥ TÃ©lÃ©charger rÃ©sultats", csv, "predictions.csv", "text/csv")
                            
                            fig = px.histogram(results_df, x='churn_probability', nbins=20, color='risk_level',
                                              color_discrete_map={'Low': '#10b981', 'Medium': '#f59e0b', 'High': '#ef4444'})
                            fig.update_layout(title="Distribution des prÃ©dictions")
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning("Aucune prÃ©diction rÃ©ussie.")
                        
            except Exception as e:
                st.error(f"Erreur: {e}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div class="footer">
        <p>ğŸ¦ Bank Churn Prediction - MLOps Workshop 2026</p>
        <p>FastAPI â€¢ Streamlit â€¢ MLflow â€¢ Azure Container Apps</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
